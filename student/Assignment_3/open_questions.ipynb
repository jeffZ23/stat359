{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c7fcefa2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Assignment 3: Sentiment Classification Reflection\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    self-contained: true\n",
    "    number-sections: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1315d13",
   "metadata": {},
   "source": [
    "1. Neither model underfit, Both hit strong training performance quickly and validation macro-F1 reaches 0.70+, so capacity + optimization are sufficient. \n",
    "Both models show mild–moderate overfitting after the mid-training point. For MLP, the train Macro F1 keep climbing while the validation Macro F1 plateau around 0.55 and wobbles. Train loss steadily decreases, but val loss stops improving and becomes noisy/spiky. For LSTM, the train loss decreces steadily, but the validation loss fluctuates fiercely while validation Macro F1 ends up good. \n",
    "\n",
    "With this dataset’s heavy class imbalance (neutral dominates), an unweighted model tends to optimize accuracy by overpredicting neutral. Using class_weight pushes the model to treat minority errors as expensive, which typically improves macro-F1 materially and increases minority-class recall/precision balance. Class weights increase the gradient contribution from rare classes. That tends to make training less smooth (more variance batch-to-batch) and make validation loss spikier, because a few confidently-wrong minority examples can dominate cross-entropy. Class weights likely raised the macro-F1 to the required level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a53b8",
   "metadata": {},
   "source": [
    "2. LSTM generalized slightly better. Evidence:\n",
    "Test Macro-F1: LSTM 0.7161 vs MLP 0.7115 (primary metric).\n",
    "LSTM: val macro-F1 0.7097 → test 0.7161 (+0.0064)\n",
    "MLP: val macro-F1 0.7202 → test 0.7115 (−0.0087)\n",
    "The LSTM’s test performance matches (and slightly exceeds) its validation performance, while the MLP drops a bit from validation to test.\n",
    "In terms of accuracy, both are close, but LSTM edges out on test macro-F1.\n",
    "\n",
    "\n",
    "Positive was misclassified the most in both models, mainly as neutral.\n",
    "\n",
    "From the confusion matrices:\n",
    "LSTM (true positive row): positive → neutral = 67, positive → negative = 25, correct = 112\n",
    "Misclassified positives = 92 out of 204, 45% error rate\n",
    "MLP (true positive row): positive → neutral = 68, positive → negative = 23, correct = 113\n",
    "Misclassified positives =  91 out of  204, 45% error rate\n",
    "Negatives and neutrals had much lower error rates.\n",
    "\n",
    "Even with class weights, the model still sees many more neutral samples, so decision boundaries often tilt toward predicting neutral when the signal is weak. Financial writing frequently frames good news cautiously (“slightly improved”, “expects growth”, “could increase”), which looks semantically close to neutral. Even “50agree” still includes sentences where annotators weren’t unanimous; borderline “neutral vs positive” is exactly where disagreement is common, so the model’s errors concentrate there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f18e3",
   "metadata": {},
   "source": [
    "3. Mean-pooling turns a sentence into a bag-of-embeddings:\n",
    "Loses word order and syntax: “profits fell despite revenue growth” and “profits grew despite revenue fall” can end up close after averaging.\n",
    "Weak on negation/contrast cues (“not”, “but”) because those cues matter via composition, not just presence.\n",
    "\n",
    "The LSTM sees the sentence as an ordered token sequence, so it can:\n",
    "model local composition (e.g., “not good”, “beat expectations”, “missed guidance”)\n",
    "use context to disambiguate words whose sentiment depends on neighbors (e.g., “risk”, “loss”, “decline” vs “loss narrowed”)\n",
    "represent contrast structure (“X improved, but Y weakened”), which mean-pooling can’t express.\n",
    "\n",
    "Yes, by a lot. From the learning curves:\n",
    "BERT val macro-F1 peaks around 0.84\n",
    "GPT val macro-F1 reaches 0.80\n",
    "This is a clear gap above the FastText baselines (0.71 for LSTM/MLP).\n",
    "Pretraining gives domain-agnostic language understanding: syntax, negation, entailment, and sentiment cues are already encoded before seeing your dataset. BERT/GPT produce different vectors for the same word in different contexts (“fall” in “fall in costs” vs “fall in revenue”).\n",
    "\n",
    "Rank(from best to worst): BERT, GPT, GRU, LSTM, MLP, RNN\n",
    "Contextual pretraining (BERT/GPT) > gated sequence modeling (GRU/LSTM) > orderless pooling (MLP) > ungated recurrence (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Use Disclosure (Required)\n",
    "\n",
    "If you used any AI-enabled tools (e.g., ChatGPT, GitHub Copilot, Claude, or other LLM assistants) while working on this assignment, you must disclose that use here. The goal is transparency-not punishment.\n",
    "\n",
    "In your disclosure, briefly include:\n",
    "- **Tool(s) used:** (name + version if known)\n",
    "- **How you used them:** (e.g., concept explanation, debugging, drafting code, rewriting text)\n",
    "- **What you verified yourself:** (e.g., reran the notebook, checked outputs/plots, checked shapes, read documentation)\n",
    "- **What you did *not* use AI for (if applicable):** (optional)\n",
    "\n",
    "You are responsible for the correctness of your submission, even if AI suggested code or explanations.\n",
    "\n",
    "#### <font color=\"red\">Write your disclosure here.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37da6f4",
   "metadata": {},
   "source": [
    "Tool used: ChatGPT 5.2 Thinking.\n",
    "How you used them: polshing sentences, define code structures, debug.\n",
    "What you verified yourself: ran the code, interpreted the outpluts and plots, read documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
